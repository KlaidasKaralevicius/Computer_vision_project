{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20ecded",
   "metadata": {},
   "source": [
    "ShanghaiTechTest\n",
    "    part_A\n",
    "        test_data (count 5)\n",
    "            ground_truth\n",
    "                GT_IMG_{1}.mat\n",
    "            images\n",
    "                IMG_{1}.jpg\n",
    "        train_data (count 20)\n",
    "            ground_truth\n",
    "                GT_IMG_{1}.mat\n",
    "            images\n",
    "                IMG_{1}.jpg\n",
    ".mat \n",
    "    Nx2 vectors of each person's head x and y coordinates\n",
    "    N - how many people there are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f5fc4",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c070f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cec31",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383fdd7",
   "metadata": {},
   "source": [
    "test/train sets already given, need to just take the correct pairs and extract crowd count from matlab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8af3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat file and return x,y coordinates of each persons head\n",
    "def load_gt_mat(mat_path):\n",
    "    mat = loadmat(mat_path)\n",
    "    return mat['image_info'][0][0][0][0][0]\n",
    "\n",
    "# load image and ground truth coords\n",
    "def load_sample(img_path, gt_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gt_coords = load_gt_mat(gt_path)\n",
    "    return img, gt_coords\n",
    "\n",
    "# load dataset (train or test set with image and corresponding ground truth)\n",
    "def load_dataset(base_path, dataset_type):\n",
    "    data = []\n",
    "    img_dir = os.path.join(base_path, f'{dataset_type}_data', 'images')\n",
    "    gt_dir = os.path.join(base_path, f'{dataset_type}_data', 'ground-truth')\n",
    "    \n",
    "    # get matching .mat and .jpg\n",
    "    for img_file in os.listdir(img_dir):\n",
    "        if img_file.endswith('.jpg'):\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            gt_file = 'GT_' + img_file.replace('.jpg', '.mat')\n",
    "            gt_path = os.path.join(gt_dir, gt_file)\n",
    "            \n",
    "            if os.path.exists(gt_path):\n",
    "                image, gt_coords = load_sample(img_path, gt_path)\n",
    "                data.append((image, gt_coords))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc03ceb",
   "metadata": {},
   "source": [
    "load data and get validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe1fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets and get validation est\n",
    "base_path = 'ShanghaiTechTest/part_A'\n",
    "\n",
    "train_data = load_dataset(base_path, 'train')\n",
    "test_data = load_dataset(base_path, 'test')\n",
    "\n",
    "train_images, val_images, train_gts, val_gts = train_test_split(\n",
    "    [item[0] for item in train_data],\n",
    "    [item[1] for item in train_data],\n",
    "    test_size = 0.2,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536fea1",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6ada8",
   "metadata": {},
   "source": [
    "#### grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5062e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(image):\n",
    "    return [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in image]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6a1e2",
   "metadata": {},
   "source": [
    "#### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41573dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return [img / 255.0 for img in image]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b096506d",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02bc881",
   "metadata": {},
   "source": [
    "randomly change: contrast, brightness or rotate +-15 degrees\n",
    "P.S. - when applying rotation change head coords to keep the link between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_img(img, gt_coords):\n",
    "    alpha = random.uniform(0.8, 1.2) # contrast\n",
    "    beta = random.uniform(-20, 20) # brightness\n",
    "    \n",
    "    # rotation\n",
    "    angle = random.uniform(-15, 15)\n",
    "    h, w = img.shape[:2]\n",
    "    matrix = cv2.getRotationMatrix2D(w / 2, h / 2), angle, 1.0)\n",
    "    img = cv2.warpAffine(img, matrix, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "    \n",
    "    # transform coords matrix for density map\n",
    "    rot_rad = np.deg2rad(angle)\n",
    "    matrix_coord = np.array([\n",
    "        [np.cos(rot_rad), -np.sin(rot_rad)],\n",
    "        [np.sin(rot_rad), np.cos(rot_rad)]\n",
    "    ])\n",
    "    \n",
    "    # transform coords\n",
    "    gt_coords = np.array(gt_coords) - [w / 2, h / 2] # center\n",
    "    gt_coords = (matrix_coord @ gt_coords.T).T # rotate\n",
    "    gt_coords = gt_coords + [w / 2, h / 2]\n",
    "    return img, gt_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78810086",
   "metadata": {},
   "source": [
    "## Generate density map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bed31",
   "metadata": {},
   "source": [
    "counting 1 to 1 on image (each human) is tricky becous a lot of overlaping, density map instead calculates how many 'mass' in the area, brighter heatmap - more people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943178ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convetr head coords to density map\n",
    "def generate_density_map(gt_coords, img_shape, sigma=4.0):\n",
    "    # blank map\n",
    "    density_map = np.zeros(img_shape[:2], dtype=np.float32)\n",
    "    # find each coordinate and mark it as 1.0\n",
    "    for x, y in gt_coords:\n",
    "        x, y = int(round(x)), int(round(y))\n",
    "        if 0 <= x < img_shape[1] and 0 <= y < img_shape[0]:\n",
    "            density_map[y, x] = 1.0\n",
    "    \n",
    "    # change point annotation to gaussian blob\n",
    "    density_map = cv2.GaussianBlur(density_map, (15, 15), sigma)\n",
    "    # make sure that density map doesn't excel real number of heads\n",
    "    density_map *= (np.sum(density_map) / len(gt_coords))\n",
    "    return density_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dae956",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6af4f0",
   "metadata": {},
   "source": [
    "#### HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07fa897",
   "metadata": {},
   "source": [
    "hog good for human silhouete detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48bbca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_features(img, orientations=9, px_per_cell=(4, 4), cells_per_block=(2, 2)):\n",
    "    features, hog_img = hog(\n",
    "        img,\n",
    "        orientations = orientations, # in how many parts 0-180 degrees divided - 20, 40, 60 ..., 180\n",
    "        pixels_per_cell = px_per_cell, # smaller value - finer details (good for bigger crowds/smaller images)\n",
    "        cells_per_block = cells_per_block, # bigger blocks learn more spatial context\n",
    "        visualize = True,\n",
    "        block_norm = 'L2-Hys' # normalisation model\n",
    "    )\n",
    "    # features - flat HOG descriptors, hog_img - visual of dominant gradients per cell\n",
    "    return features, hog_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3d4e8",
   "metadata": {},
   "source": [
    "#### LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bdf8fd",
   "metadata": {},
   "source": [
    "gets texture, helps seperate people from environment - clothing or hair have different texture from concrete or car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114bce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_features(img, radius=4, n_points=24, method='uniform'):\n",
    "    lbp = local_binary_pattern(\n",
    "        img, \n",
    "        P = n_points, # compares pixel to other pixels in 24 directions\n",
    "        R = radius, # after which radius to check pixels\n",
    "        method = method\n",
    "    )\n",
    "    \n",
    "    hist, _ = np.histogram(lbp, density=True, bins=n_points+2, range=(0, n_points+2))  \n",
    "    # lbp - texture map, hist - normalized historgram of pattern frequency \n",
    "    return lbp, hist "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71697111",
   "metadata": {},
   "source": [
    "#### Multi-scale features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d3bc5",
   "metadata": {},
   "source": [
    "find each previous feature on different scale img - 1, 1/2, 1/4, so model can learn to detect small, normal and big people on same image (good when there is big crowd - some people at far distance, some near the camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7272c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect donwscaled img of original img (have 1/1, 1/2 and 1/4 of same image)\n",
    "def gaussian_pyramid(img, scales=[1.0, 0.5, 0.25]):\n",
    "    pyramid = []\n",
    "    for scale in scales:\n",
    "        if scale == 1.0:\n",
    "            pyramid.append(img)\n",
    "        else:\n",
    "            resized = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "            pyramid.append(resized)\n",
    "    return pyramid\n",
    "\n",
    "# extrat features(hog, lbp) at different resolutions (1, 1/2, 1/4)\n",
    "def multi_scale_features(img, scales=[1.0, 0.5, 0.25]):\n",
    "    pyramid = gaussian_pyramid(img, scales)\n",
    "    features = {\n",
    "        'hog': [],\n",
    "        'lbp': []\n",
    "    }\n",
    "    \n",
    "    for scaled_img in enumerate(pyramid):\n",
    "        hog_feats, _ = hog_features(scaled_img)\n",
    "        features['hog'].append(hog_feats)\n",
    "        \n",
    "        _, lbp_hist = lbp_features(scaled_img)\n",
    "        features['lbp'].append(lbp_hist)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d74a8",
   "metadata": {},
   "source": [
    "## Classification (SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4563d2c",
   "metadata": {},
   "source": [
    "#### train predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e93330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d427bd33",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77959d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a6db185",
   "metadata": {},
   "source": [
    "## Results (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18213e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
